#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de mise √† jour automatique des avis Vinted
√Ä ex√©cuter p√©riodiquement pour r√©cup√©rer les nouveaux avis
"""

import json
import logging
import sys
from pathlib import Path
from datetime import datetime
import time

# Import du scraper complet
from complete_vinted_scraper import CompleteVintedReviewsScraper

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('auto_update_reviews.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class VintedReviewsUpdater:
    def __init__(self):
        self.reviews_file = Path("data/reviews.json")
        self.backup_dir = Path("data/backups")
        self.backup_dir.mkdir(exist_ok=True)
    
    def load_current_reviews(self):
        """Charge les avis actuels"""
        if not self.reviews_file.exists():
            return []
        
        try:
            with open(self.reviews_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('reviews', [])
        except Exception as e:
            logger.error(f"‚ùå Erreur lecture reviews.json: {e}")
            return []
    
    def backup_current_reviews(self):
        """Sauvegarde les avis actuels"""
        if not self.reviews_file.exists():
            logger.info("‚ÑπÔ∏è Pas de fichier de reviews √† sauvegarder")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"reviews_backup_{timestamp}.json"
        
        try:
            import shutil
            shutil.copy2(self.reviews_file, backup_file)
            logger.info(f"üíæ Sauvegarde: {backup_file}")
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde: {e}")
    
    def compare_reviews(self, current_reviews, new_reviews):
        """Compare les avis actuels avec les nouveaux"""
        current_comments = {review.get('comment', '') for review in current_reviews}
        new_comments = {review.get('comment', '') for review in new_reviews}
        
        # Nouveaux avis
        truly_new = [review for review in new_reviews 
                    if review.get('comment', '') not in current_comments]
        
        logger.info(f"üìä Comparaison:")
        logger.info(f"  - Avis actuels: {len(current_reviews)}")
        logger.info(f"  - Avis scrap√©s: {len(new_reviews)}")
        logger.info(f"  - Nouveaux avis: {len(truly_new)}")
        
        if truly_new:
            logger.info("üÜï Nouveaux avis trouv√©s:")
            for review in truly_new:
                logger.info(f"  ‚Ä¢ [{review.get('username', 'Anonyme')}] {review.get('comment', '')[:50]}...")
        
        return truly_new
    
    def update_reviews_if_needed(self, new_reviews):
        """Met √† jour les avis si n√©cessaire"""
        current_reviews = self.load_current_reviews()
        truly_new = self.compare_reviews(current_reviews, new_reviews)
        
        if not truly_new:
            logger.info("‚úÖ Aucun nouvel avis, pas de mise √† jour n√©cessaire")
            return False
        
        # Faire une sauvegarde
        self.backup_current_reviews()
        
        # Combiner tous les avis (nouveaux + existants)
        all_reviews = new_reviews  # Prendre tous les avis scrap√©s comme r√©f√©rence
        
        # Reformater pour l'ID
        for i, review in enumerate(all_reviews):
            review['id'] = i + 1
        
        # Cr√©er la structure finale
        reviews_data = {
            "last_updated": datetime.now().isoformat(),
            "source": "vinted_real_scraper_auto",
            "total_reviews": len(all_reviews),
            "new_reviews_count": len(truly_new),
            "reviews": all_reviews
        }
        
        # Sauvegarder
        with open(self.reviews_file, 'w', encoding='utf-8') as f:
            json.dump(reviews_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ Avis mis √† jour: {len(all_reviews)} total ({len(truly_new)} nouveaux)")
        return True
    
    def run_update(self):
        """Ex√©cute une mise √† jour compl√®te"""
        logger.info("üîÑ MISE √Ä JOUR AUTOMATIQUE DES AVIS VINTED")
        logger.info("="*50)
        
        try:
            # 1. Scraper les avis actuels
            logger.info("üï∑Ô∏è Scraping des avis...")
            scraper = CompleteVintedReviewsScraper()
            new_reviews = scraper.run()
            
            if not new_reviews:
                logger.error("‚ùå Aucun avis r√©cup√©r√©")
                return False
            
            # 2. Comparer et mettre √† jour si n√©cessaire
            updated = self.update_reviews_if_needed(new_reviews)
            
            # 3. R√©sum√©
            if updated:
                logger.info("üéâ MISE √Ä JOUR TERMIN√âE AVEC SUCC√àS!")
                
                # Afficher un r√©sum√© des avis
                logger.info("\nüìù AVIS ACTUELS:")
                for i, review in enumerate(new_reviews, 1):
                    logger.info(f"  {i}. [{review['username']}] {review['comment']}")
            else:
                logger.info("‚úÖ Pas de mise √† jour n√©cessaire")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la mise √† jour: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """Fonction principale"""
    updater = VintedReviewsUpdater()
    success = updater.run_update()
    
    if success:
        logger.info("üèÅ Mise √† jour termin√©e")
    else:
        logger.error("‚ùå √âchec de la mise √† jour")
        sys.exit(1)

if __name__ == "__main__":
    main()